{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from empiricaldist import Pmf, Cdf\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline  \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "# for one hot encoding with feature-engine\n",
    "from feature_engine.categorical_encoders import OneHotCategoricalEncoder\n",
    "from feature_engine.categorical_encoders import RareLabelCategoricalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_log_error \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "import scipy.stats as stats\n",
    "from feature_engine import variable_transformers as vt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform type\n",
    "\n",
    "train_data[[\"MoSold\", \"MSSubClass\"]] = train_data[[\"MoSold\", \"MSSubClass\"]].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate object and numerical columns. Separate area and surface area columns and year columns as wel\n",
    "\n",
    "cat_cols = [x for x in train_data.columns if train_data[x].dtype==np.object]\n",
    "num_cols = [x for x in train_data.columns if train_data[x].dtype!=np.object]\n",
    "area_cols = [x for x in train_data.columns if (\"SF\" in x)|(\"Area\" in x)|(x==\"LotFrontage\")]\n",
    "year_cols = [x for x in num_cols if 'Yr' in x or 'Year' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1314, 79), (146, 79))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data.drop(['Id', 'SalePrice'], axis=1),\n",
    "                                                    train_data['SalePrice'],\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate elapsed time\n",
    "\n",
    "def elapsed_years(df, cols):\n",
    "    # capture difference between year col and\n",
    "    # year the house was sold\n",
    "    for col in cols:\n",
    "        if col=='YrSold':\n",
    "            continue\n",
    "        df[col] = df['YrSold'] - df[col]\n",
    "   \n",
    "    return df\n",
    "\n",
    "X_train = elapsed_years(X_train, year_cols)\n",
    "X_test = elapsed_years(X_test, year_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1314 entries, 930 to 684\n",
      "Data columns (total 79 columns):\n",
      "MSSubClass       1314 non-null object\n",
      "MSZoning         1314 non-null object\n",
      "LotFrontage      1081 non-null float64\n",
      "LotArea          1314 non-null int64\n",
      "Street           1314 non-null object\n",
      "Alley            81 non-null object\n",
      "LotShape         1314 non-null object\n",
      "LandContour      1314 non-null object\n",
      "Utilities        1314 non-null object\n",
      "LotConfig        1314 non-null object\n",
      "LandSlope        1314 non-null object\n",
      "Neighborhood     1314 non-null object\n",
      "Condition1       1314 non-null object\n",
      "Condition2       1314 non-null object\n",
      "BldgType         1314 non-null object\n",
      "HouseStyle       1314 non-null object\n",
      "OverallQual      1314 non-null int64\n",
      "OverallCond      1314 non-null int64\n",
      "YearBuilt        1314 non-null int64\n",
      "YearRemodAdd     1314 non-null int64\n",
      "RoofStyle        1314 non-null object\n",
      "RoofMatl         1314 non-null object\n",
      "Exterior1st      1314 non-null object\n",
      "Exterior2nd      1314 non-null object\n",
      "MasVnrType       1308 non-null object\n",
      "MasVnrArea       1308 non-null float64\n",
      "ExterQual        1314 non-null object\n",
      "ExterCond        1314 non-null object\n",
      "Foundation       1314 non-null object\n",
      "BsmtQual         1282 non-null object\n",
      "BsmtCond         1282 non-null object\n",
      "BsmtExposure     1281 non-null object\n",
      "BsmtFinType1     1282 non-null object\n",
      "BsmtFinSF1       1314 non-null int64\n",
      "BsmtFinType2     1281 non-null object\n",
      "BsmtFinSF2       1314 non-null int64\n",
      "BsmtUnfSF        1314 non-null int64\n",
      "TotalBsmtSF      1314 non-null int64\n",
      "Heating          1314 non-null object\n",
      "HeatingQC        1314 non-null object\n",
      "CentralAir       1314 non-null object\n",
      "Electrical       1313 non-null object\n",
      "1stFlrSF         1314 non-null int64\n",
      "2ndFlrSF         1314 non-null int64\n",
      "LowQualFinSF     1314 non-null int64\n",
      "GrLivArea        1314 non-null int64\n",
      "BsmtFullBath     1314 non-null int64\n",
      "BsmtHalfBath     1314 non-null int64\n",
      "FullBath         1314 non-null int64\n",
      "HalfBath         1314 non-null int64\n",
      "BedroomAbvGr     1314 non-null int64\n",
      "KitchenAbvGr     1314 non-null int64\n",
      "KitchenQual      1314 non-null object\n",
      "TotRmsAbvGrd     1314 non-null int64\n",
      "Functional       1314 non-null object\n",
      "Fireplaces       1314 non-null int64\n",
      "FireplaceQu      693 non-null object\n",
      "GarageType       1240 non-null object\n",
      "GarageYrBlt      1240 non-null float64\n",
      "GarageFinish     1240 non-null object\n",
      "GarageCars       1314 non-null int64\n",
      "GarageArea       1314 non-null int64\n",
      "GarageQual       1240 non-null object\n",
      "GarageCond       1240 non-null object\n",
      "PavedDrive       1314 non-null object\n",
      "WoodDeckSF       1314 non-null int64\n",
      "OpenPorchSF      1314 non-null int64\n",
      "EnclosedPorch    1314 non-null int64\n",
      "3SsnPorch        1314 non-null int64\n",
      "ScreenPorch      1314 non-null int64\n",
      "PoolArea         1314 non-null int64\n",
      "PoolQC           6 non-null object\n",
      "Fence            244 non-null object\n",
      "MiscFeature      51 non-null object\n",
      "MiscVal          1314 non-null int64\n",
      "MoSold           1314 non-null object\n",
      "YrSold           1314 non-null int64\n",
      "SaleType         1314 non-null object\n",
      "SaleCondition    1314 non-null object\n",
      "dtypes: float64(3), int64(31), object(45)\n",
      "memory usage: 821.2+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets drop YrSold\n",
    "\n",
    "X_train.drop(['YrSold', 'MiscVal'], axis=1, inplace=True)\n",
    "X_test.drop(['YrSold', 'MiscVal'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotFrontage 0.17732115677321156\n",
      "Alley 0.9383561643835616\n",
      "MasVnrType 0.0045662100456621\n",
      "MasVnrArea 0.0045662100456621\n",
      "BsmtQual 0.0243531202435312\n",
      "BsmtCond 0.0243531202435312\n",
      "BsmtExposure 0.02511415525114155\n",
      "BsmtFinType1 0.0243531202435312\n",
      "BsmtFinType2 0.02511415525114155\n",
      "Electrical 0.00076103500761035\n",
      "FireplaceQu 0.4726027397260274\n",
      "GarageType 0.0563165905631659\n",
      "GarageYrBlt 0.0563165905631659\n",
      "GarageFinish 0.0563165905631659\n",
      "GarageQual 0.0563165905631659\n",
      "GarageCond 0.0563165905631659\n",
      "PoolQC 0.9954337899543378\n",
      "Fence 0.8143074581430746\n",
      "MiscFeature 0.9611872146118722\n"
     ]
    }
   ],
   "source": [
    "# lets check missing values\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].isnull().sum() > 0:\n",
    "        print(col, X_train[col].isnull().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute numerical cols with median value\n",
    "\n",
    "# define an imputation function\n",
    "def impute_na_median(df, cols):\n",
    "    for col in cols:\n",
    "        df[col]= df[col].fillna(df[col].median())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# apply on train set and test set\n",
    "X_train_imp = impute_na_median(X_train, cols=['LotFrontage', 'MasVnrArea', 'GarageYrBlt'])\n",
    "X_test_imp = impute_na_median(X_test, cols=['LotFrontage', 'MasVnrArea', 'GarageYrBlt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute cat cols with a 'NA' label\n",
    "\n",
    "# define an imputation function\n",
    "def impute_na_label(df, cols):\n",
    "    for col in cols:\n",
    "        df[col]= df[col].fillna('NA')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# apply on train set and test set\n",
    "X_train_imp = impute_na_label(X_train_imp, cols=cat_cols)\n",
    "X_test_imp = impute_na_label(X_test_imp, cols=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LotFrontage': 0.422432655023388, 'LotArea': -12.55283001172003, 'MasVnrArea': -0.25336100411247126, 'BsmtFinSF1': 0.2241603622191745, 'BsmtFinSF2': -1.5253670841536835, 'BsmtUnfSF': 0.4741451871581765, 'TotalBsmtSF': 0.7320141644679369, '1stFlrSF': -12.55283001172003, '2ndFlrSF': -0.12038141633304861, 'LowQualFinSF': -9.769635009367672, 'GrLivArea': 0.03602357773149543, 'GarageArea': 0.8072365473023602, 'WoodDeckSF': -0.08553433814930124, 'OpenPorchSF': 0.015647864654396017, 'PoolArea': -34.48045639184592}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dina/house-prices-advanced/venv/lib/python3.8/site-packages/scipy/stats/morestats.py:1478: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(trans.var(axis=0))\n",
      "/Users/dina/house-prices-advanced/venv/lib/python3.8/site-packages/scipy/optimize/optimize.py:2371: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  w = xb - ((xb - xc) * tmp2 - (xb - xa) * tmp1) / denom\n",
      "/Users/dina/house-prices-advanced/venv/lib/python3.8/site-packages/scipy/optimize/optimize.py:1984: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tmp1 = (x - w) * (fx - fv)\n",
      "/Users/dina/house-prices-advanced/venv/lib/python3.8/site-packages/scipy/optimize/optimize.py:1985: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tmp2 = (x - v) * (fx - fw)\n"
     ]
    }
   ],
   "source": [
    "# transform the area columns to enhance skew\n",
    "\n",
    "yjt = vt.YeoJohnsonTransformer(variables = area_cols)\n",
    "yjt.fit(X_train_imp)\n",
    "print(yjt.lambda_dict_)\n",
    "X_train_imp_tr = yjt.transform(X_train_imp)\n",
    "X_test_imp_tr = yjt.transform(X_test_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply rare label encoding on some of the cat cols\n",
    "\n",
    "rare_encoder = RareLabelCategoricalEncoder(\n",
    "    tol=0.05,  # minimal percentage to be considered non-rare\n",
    "    n_categories=3, # minimal number of categories the variable should have to re-cgroup rare categories\n",
    "    variables=cat_cols # apply to all categorical columns\n",
    ") \n",
    "\n",
    "rare_encoder.fit(X_train_imp_tr)\n",
    "X_train_imp_tr_enc = rare_encoder.transform(X_train_imp_tr)\n",
    "X_test_imp_tr_enc = rare_encoder.transform(X_test_imp_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSSubClass': Index(['20', '60', '50', '120'], dtype='object'),\n",
       " 'MSZoning': Index(['RL', 'RM'], dtype='object'),\n",
       " 'Street': array(['Pave', 'Grvl'], dtype=object),\n",
       " 'Alley': array(['NA', 'Grvl', 'Pave'], dtype=object),\n",
       " 'LotShape': Index(['Reg', 'IR1'], dtype='object'),\n",
       " 'LandContour': Index(['Lvl'], dtype='object'),\n",
       " 'Utilities': array(['AllPub', 'NoSeWa'], dtype=object),\n",
       " 'LotConfig': Index(['Inside', 'Corner', 'CulDSac'], dtype='object'),\n",
       " 'LandSlope': array(['Gtl', 'Mod', 'Sev'], dtype=object),\n",
       " 'Neighborhood': Index(['NAmes', 'CollgCr', 'OldTown', 'Edwards', 'Somerst', 'NridgHt',\n",
       "        'Gilbert', 'Sawyer'],\n",
       "       dtype='object'),\n",
       " 'Condition1': Index(['Norm', 'Feedr'], dtype='object'),\n",
       " 'Condition2': Index(['Norm'], dtype='object'),\n",
       " 'BldgType': Index(['1Fam', 'TwnhsE'], dtype='object'),\n",
       " 'HouseStyle': Index(['1Story', '2Story', '1.5Fin'], dtype='object'),\n",
       " 'RoofStyle': Index(['Gable', 'Hip'], dtype='object'),\n",
       " 'RoofMatl': Index(['CompShg'], dtype='object'),\n",
       " 'Exterior1st': Index(['VinylSd', 'HdBoard', 'Wd Sdng', 'MetalSd', 'Plywood'], dtype='object'),\n",
       " 'Exterior2nd': Index(['VinylSd', 'Wd Sdng', 'HdBoard', 'MetalSd', 'Plywood'], dtype='object'),\n",
       " 'MasVnrType': Index(['None', 'BrkFace', 'Stone'], dtype='object'),\n",
       " 'ExterQual': Index(['TA', 'Gd'], dtype='object'),\n",
       " 'ExterCond': Index(['TA', 'Gd'], dtype='object'),\n",
       " 'Foundation': Index(['PConc', 'CBlock', 'BrkTil'], dtype='object'),\n",
       " 'BsmtQual': Index(['TA', 'Gd', 'Ex'], dtype='object'),\n",
       " 'BsmtCond': Index(['TA'], dtype='object'),\n",
       " 'BsmtExposure': Index(['No', 'Av', 'Gd', 'Mn'], dtype='object'),\n",
       " 'BsmtFinType1': Index(['Unf', 'GLQ', 'ALQ', 'BLQ', 'Rec'], dtype='object'),\n",
       " 'BsmtFinType2': Index(['Unf'], dtype='object'),\n",
       " 'Heating': Index(['GasA'], dtype='object'),\n",
       " 'HeatingQC': Index(['Ex', 'TA', 'Gd'], dtype='object'),\n",
       " 'CentralAir': array(['Y', 'N'], dtype=object),\n",
       " 'Electrical': Index(['SBrkr', 'FuseA'], dtype='object'),\n",
       " 'KitchenQual': Index(['TA', 'Gd', 'Ex'], dtype='object'),\n",
       " 'Functional': Index(['Typ'], dtype='object'),\n",
       " 'FireplaceQu': Index(['NA', 'Gd', 'TA'], dtype='object'),\n",
       " 'GarageType': Index(['Attchd', 'Detchd', 'BuiltIn', 'NA'], dtype='object'),\n",
       " 'GarageFinish': Index(['Unf', 'RFn', 'Fin', 'NA'], dtype='object'),\n",
       " 'GarageQual': Index(['TA', 'NA'], dtype='object'),\n",
       " 'GarageCond': Index(['TA', 'NA'], dtype='object'),\n",
       " 'PavedDrive': array(['Y', 'N', 'P'], dtype=object),\n",
       " 'PoolQC': Index(['NA'], dtype='object'),\n",
       " 'Fence': Index(['NA', 'MnPrv'], dtype='object'),\n",
       " 'MiscFeature': Index(['NA'], dtype='object'),\n",
       " 'MoSold': Index(['6', '7', '5', '4', '8', '3', '10', '11'], dtype='object'),\n",
       " 'SaleType': Index(['WD', 'New'], dtype='object'),\n",
       " 'SaleCondition': Index(['Normal', 'Partial', 'Abnorml'], dtype='object')}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_encoder.encoder_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply hot one encoding next\n",
    "\n",
    "ohe_enc = OneHotCategoricalEncoder(\n",
    "    top_categories=None,\n",
    "    drop_last=False) # automatically detects all cat vars in data\n",
    "\n",
    "ohe_enc.fit(X_train_imp_tr_enc)\n",
    "\n",
    "X_train_imp_tr_enc = ohe_enc.transform(X_train_imp_tr_enc)\n",
    "X_test_imp_tr_enc = ohe_enc.transform(X_test_imp_tr_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1314 entries, 930 to 684\n",
      "Columns: 192 entries, LotFrontage to SaleCondition_Abnorml\n",
      "dtypes: float64(16), int64(176)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "X_train_imp_tr_enc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 146 entries, 529 to 310\n",
      "Columns: 192 entries, LotFrontage to SaleCondition_Abnorml\n",
      "dtypes: float64(16), int64(176)\n",
      "memory usage: 220.1 KB\n"
     ]
    }
   ],
   "source": [
    "X_test_imp_tr_enc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets skip scaling since we will use light gbm\n",
    "\n",
    "lightgbm_regr = LGBMRegressor()\n",
    "\n",
    "lightgbm_regr.fit(X_train_imp_tr_enc, y_train)\n",
    "\n",
    "y_pred_train = lightgbm_regr.predict(X_train_imp_tr_enc)\n",
    "y_pred_test = lightgbm_regr.predict(X_test_imp_tr_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse: 147693255.35459948\n",
      "train rmse: 12152.911394172159\n",
      "train r2: 0.9763457347548624\n",
      "\n",
      "test mse: 1236729646.478677\n",
      "test rmse: 35167.16716596145\n",
      "test rmsle: 0.1300077902257026\n",
      "test r2: 0.8200365397127115\n"
     ]
    }
   ],
   "source": [
    "# check model performance:\n",
    "\n",
    "print('train mse: {}'.format(mean_squared_error(y_train, y_pred_train)))\n",
    "print('train rmse: {}'.format(np.sqrt(mean_squared_error(y_train, y_pred_train))))\n",
    "print('train r2: {}'.format(r2_score(y_train, y_pred_train)))\n",
    "#print('train rmsle: {}'.format(np.sqrt(mean_squared_error(np.log(y_train), np.log(y_pred_train)))))\n",
    "print()\n",
    "print('test mse: {}'.format(mean_squared_error(y_test, y_pred_test)))\n",
    "print('test rmse: {}'.format(np.sqrt(mean_squared_error(y_test, y_pred_test))))\n",
    "print('test rmsle: {}'.format(np.sqrt(mean_squared_error(np.log(y_test), np.log(y_pred_test)))))\n",
    "print('test r2: {}'.format(r2_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add scaling to see if there is a difference\n",
    "\n",
    "# scaling the features since we will be using LR\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_imp_tr_enc)\n",
    "\n",
    "# transform \n",
    "X_train_imp_tr_enc_sc = scaler.transform(X_train_imp_tr_enc)\n",
    "X_test_imp_tr_enc_sc = scaler.transform(X_test_imp_tr_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_regr = LGBMRegressor()\n",
    "\n",
    "lightgbm_regr.fit(X_train_imp_tr_enc_sc, y_train)\n",
    "\n",
    "y_pred_train = lightgbm_regr.predict(X_train_imp_tr_enc_sc)\n",
    "y_pred_test = lightgbm_regr.predict(X_test_imp_tr_enc_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse: 145963260.1377637\n",
      "train rmse: 12081.525571622307\n",
      "train r2: 0.9766228074325117\n",
      "train rmsle: 0.0580950897471909\n",
      "\n",
      "test mse: 1177202724.236507\n",
      "test rmse: 34310.38799309193\n",
      "test rmsle: 0.12405642445651678\n",
      "test r2: 0.8286986356990536\n"
     ]
    }
   ],
   "source": [
    "print('train mse: {}'.format(mean_squared_error(y_train, y_pred_train)))\n",
    "print('train rmse: {}'.format(np.sqrt(mean_squared_error(y_train, y_pred_train))))\n",
    "print('train r2: {}'.format(r2_score(y_train, y_pred_train)))\n",
    "print('train rmsle: {}'.format(np.sqrt(mean_squared_error(np.log(y_train), np.log(y_pred_train)))))\n",
    "print()\n",
    "print('test mse: {}'.format(mean_squared_error(y_test, y_pred_test)))\n",
    "print('test rmse: {}'.format(np.sqrt(mean_squared_error(y_test, y_pred_test))))\n",
    "print('test rmsle: {}'.format(np.sqrt(mean_squared_error(np.log(y_test), np.log(y_pred_test)))))\n",
    "print('test r2: {}'.format(r2_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For lambda = 0.001\n",
      "train rmsle: 0.05781990984584178\n",
      "test rmsle: 0.124548629208967\n",
      "\n",
      "For lambda = 0.01\n",
      "train rmsle: 0.05781991142680559\n",
      "test rmsle: 0.12454862894909223\n",
      "\n",
      "For lambda = 0.1\n",
      "train rmsle: 0.057147165752472896\n",
      "test rmsle: 0.12370177208429929\n",
      "\n",
      "For lambda = 1.0\n",
      "train rmsle: 0.05743526025068686\n",
      "test rmsle: 0.12266215282760119\n",
      "\n",
      "For lambda = 10\n",
      "train rmsle: 0.057906482825402984\n",
      "test rmsle: 0.12359304609634947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# there is clearly a lot of overfitting, so we can try to introduce regularization\n",
    "\n",
    "# tune the lamda_l1 value \n",
    "\n",
    "lambdas=[1e-3, 1e-2, 0.1, 1.0, 10]\n",
    "\n",
    "for lambda_value in lambdas:\n",
    "    lightgbm_regr = LGBMRegressor(lambda_l1=lambda_value)    \n",
    "    lightgbm_regr.fit(X_train_imp_tr_enc_sc, y_train)\n",
    "\n",
    "    y_pred_train = lightgbm_regr.predict(X_train_imp_tr_enc_sc)\n",
    "    y_pred_test = lightgbm_regr.predict(X_test_imp_tr_enc_sc)\n",
    "   \n",
    "    print(\"For lambda = {}\".format(lambda_value))\n",
    "    #print('train mse: {}'.format(mean_squared_error(y_train, y_pred_train)))\n",
    "    #print('train rmse: {}'.format(np.sqrt(mean_squared_error(y_train, y_pred_train))))\n",
    "    #print('train r2: {}'.format(r2_score(y_train, y_pred_train)))\n",
    "    print('train rmsle: {}'.format(np.sqrt(mean_squared_error(np.log(y_train), np.log(y_pred_train)))))\n",
    "    #print('test mse: {}'.format(mean_squared_error(y_test, y_pred_test)))\n",
    "    #print('test rmse: {}'.format(np.sqrt(mean_squared_error(y_test, y_pred_test))))\n",
    "    print('test rmsle: {}'.format(np.sqrt(mean_squared_error(np.log(y_test), np.log(y_pred_test)))))\n",
    "    #print('test r2: {}'.format(r2_score(y_test, y_pred_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For feature_fraction = 0.1\n",
      "train rmsle: 0.08135332635939375\n",
      "test rmsle: 0.12742341337047783\n",
      "\n",
      "For feature_fraction = 0.2\n",
      "train rmsle: 0.06767824128092653\n",
      "test rmsle: 0.12393654726914535\n",
      "\n",
      "For feature_fraction = 0.30000000000000004\n",
      "train rmsle: 0.06504597610445007\n",
      "test rmsle: 0.11828561041520136\n",
      "\n",
      "For feature_fraction = 0.4\n",
      "train rmsle: 0.06053329967555061\n",
      "test rmsle: 0.12176495516785761\n",
      "\n",
      "For feature_fraction = 0.5\n",
      "train rmsle: 0.05927436081153298\n",
      "test rmsle: 0.12262472571001555\n",
      "\n",
      "For feature_fraction = 0.6\n",
      "train rmsle: 0.057775411210222206\n",
      "test rmsle: 0.1193798070088095\n",
      "\n",
      "For feature_fraction = 0.7000000000000001\n",
      "train rmsle: 0.056804724123292995\n",
      "test rmsle: 0.1206026952829246\n",
      "\n",
      "For feature_fraction = 0.8\n",
      "train rmsle: 0.056705375786455674\n",
      "test rmsle: 0.12792893114679826\n",
      "\n",
      "For feature_fraction = 0.9\n",
      "train rmsle: 0.05723319965709363\n",
      "test rmsle: 0.12250496372183027\n",
      "\n",
      "For feature_fraction = 1.0\n",
      "train rmsle: 0.05743526025068686\n",
      "test rmsle: 0.12266215282760119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lambda1 = 1.0 is the best value. we can also tune other params for the model for additional regularization\n",
    "\n",
    "feature_fractions = list(np.arange(0.1,1.1,step=0.10))\n",
    "\n",
    "for frac in feature_fractions:\n",
    "    lightgbm_regr = LGBMRegressor(lambda_l1=1.0, feature_fraction=frac)    \n",
    "    lightgbm_regr.fit(X_train_imp_tr_enc_sc, y_train)\n",
    "\n",
    "    y_pred_train = lightgbm_regr.predict(X_train_imp_tr_enc_sc)\n",
    "    y_pred_test = lightgbm_regr.predict(X_test_imp_tr_enc_sc)\n",
    "   \n",
    "    print(\"For feature_fraction = {}\".format(frac))\n",
    "    #print('train mse: {}'.format(mean_squared_error(y_train, y_pred_train)))\n",
    "    #print('train rmse: {}'.format(np.sqrt(mean_squared_error(y_train, y_pred_train))))\n",
    "    #print('train r2: {}'.format(r2_score(y_train, y_pred_train)))\n",
    "    print('train rmsle: {}'.format(np.sqrt(mean_squared_error(np.log(y_train), np.log(y_pred_train)))))\n",
    "    #print('test mse: {}'.format(mean_squared_error(y_test, y_pred_test)))\n",
    "    #print('test rmse: {}'.format(np.sqrt(mean_squared_error(y_test, y_pred_test))))\n",
    "    print('test rmsle: {}'.format(np.sqrt(mean_squared_error(np.log(y_test), np.log(y_pred_test)))))\n",
    "    #print('test r2: {}'.format(r2_score(y_test, y_pred_test)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For num_leaves = 2\n",
      "train rmsle: 0.15435206893721345\n",
      "test rmsle: 0.14247334934599887\n",
      "\n",
      "For num_leaves = 5\n",
      "train rmsle: 0.1177221563670797\n",
      "test rmsle: 0.127509485079394\n",
      "\n",
      "For num_leaves = 8\n",
      "train rmsle: 0.10451851480369113\n",
      "test rmsle: 0.12585950273848398\n",
      "\n",
      "For num_leaves = 11\n",
      "train rmsle: 0.09606545689771369\n",
      "test rmsle: 0.12651946703124253\n",
      "\n",
      "For num_leaves = 14\n",
      "train rmsle: 0.08903601052772049\n",
      "test rmsle: 0.1208761868175641\n",
      "\n",
      "For num_leaves = 17\n",
      "train rmsle: 0.08293062229116341\n",
      "test rmsle: 0.11943604804103249\n",
      "\n",
      "For num_leaves = 20\n",
      "train rmsle: 0.07749923245037495\n",
      "test rmsle: 0.12285435528853468\n",
      "\n",
      "For num_leaves = 23\n",
      "train rmsle: 0.07252039249567102\n",
      "test rmsle: 0.12016821423174813\n",
      "\n",
      "For num_leaves = 26\n",
      "train rmsle: 0.06972377050966279\n",
      "test rmsle: 0.12239255047670805\n",
      "\n",
      "For num_leaves = 29\n",
      "train rmsle: 0.06614760063791958\n",
      "test rmsle: 0.12046852526536023\n",
      "\n",
      "For num_leaves = 31\n",
      "train rmsle: 0.06504597610445007\n",
      "test rmsle: 0.11828561041520136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_leaves = list(np.arange(2,31,step=3))+[31]\n",
    "\n",
    "for num in number_leaves:\n",
    "    lightgbm_regr = LGBMRegressor(lambda_l1=1.0, feature_fraction=0.30, num_leaves=num)    \n",
    "    lightgbm_regr.fit(X_train_imp_tr_enc_sc, y_train)\n",
    "\n",
    "    y_pred_train = lightgbm_regr.predict(X_train_imp_tr_enc_sc)\n",
    "    y_pred_test = lightgbm_regr.predict(X_test_imp_tr_enc_sc)\n",
    "   \n",
    "    print(\"For num_leaves = {}\".format(num))\n",
    "    #print('train mse: {}'.format(mean_squared_error(y_train, y_pred_train)))\n",
    "    #print('train rmse: {}'.format(np.sqrt(mean_squared_error(y_train, y_pred_train))))\n",
    "    #print('train r2: {}'.format(r2_score(y_train, y_pred_train)))\n",
    "    print('train rmsle: {}'.format(np.sqrt(mean_squared_error(np.log(y_train), np.log(y_pred_train)))))\n",
    "    #print('test mse: {}'.format(mean_squared_error(y_test, y_pred_test)))\n",
    "    #print('test rmse: {}'.format(np.sqrt(mean_squared_error(y_test, y_pred_test))))\n",
    "    print('test rmsle: {}'.format(np.sqrt(mean_squared_error(np.log(y_test), np.log(y_pred_test)))))\n",
    "    #print('test r2: {}'.format(r2_score(y_test, y_pred_test)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For bagging_fraction = 0.1\n",
      "train rmsle: 0.15371949783556577\n",
      "test rmsle: 0.14693591409768206\n",
      "\n",
      "For bagging_fraction = 0.2\n",
      "train rmsle: 0.12828640393671362\n",
      "test rmsle: 0.12705526106332884\n",
      "\n",
      "For bagging_fraction = 0.30000000000000004\n",
      "train rmsle: 0.11040022227172241\n",
      "test rmsle: 0.12259481164071746\n",
      "\n",
      "For bagging_fraction = 0.4\n",
      "train rmsle: 0.09892089650076027\n",
      "test rmsle: 0.12078098637928553\n",
      "\n",
      "For bagging_fraction = 0.5\n",
      "train rmsle: 0.0883559672264315\n",
      "test rmsle: 0.11693532175847905\n",
      "\n",
      "For bagging_fraction = 0.6\n",
      "train rmsle: 0.081259027161325\n",
      "test rmsle: 0.11956489522614754\n",
      "\n",
      "For bagging_fraction = 0.7000000000000001\n",
      "train rmsle: 0.07343466148600492\n",
      "test rmsle: 0.1191041865144283\n",
      "\n",
      "For bagging_fraction = 0.8\n",
      "train rmsle: 0.06906120450935284\n",
      "test rmsle: 0.11856358406523869\n",
      "\n",
      "For bagging_fraction = 0.9\n",
      "train rmsle: 0.06681459627417624\n",
      "test rmsle: 0.12007506385212889\n",
      "\n",
      "For bagging_fraction = 1.0\n",
      "train rmsle: 0.06504597610445007\n",
      "test rmsle: 0.11828561041520136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bagging_fractions = list(np.arange(0.1,1.1,step=0.10))\n",
    "\n",
    "for frac in bagging_fractions:\n",
    "    lightgbm_regr = LGBMRegressor(lambda_l1=1.0, feature_fraction=0.30, num_leaves=31, bagging_fraction=frac, \n",
    "                                 bagging_freq=5)    \n",
    "    lightgbm_regr.fit(X_train_imp_tr_enc_sc, y_train)\n",
    "\n",
    "    y_pred_train = lightgbm_regr.predict(X_train_imp_tr_enc_sc)\n",
    "    y_pred_test = lightgbm_regr.predict(X_test_imp_tr_enc_sc)\n",
    "   \n",
    "    print(\"For bagging_fraction = {}\".format(frac))\n",
    "    #print('train mse: {}'.format(mean_squared_error(y_train, y_pred_train)))\n",
    "    #print('train rmse: {}'.format(np.sqrt(mean_squared_error(y_train, y_pred_train))))\n",
    "    #print('train r2: {}'.format(r2_score(y_train, y_pred_train)))\n",
    "    print('train rmsle: {}'.format(np.sqrt(mean_squared_error(np.log(y_train), np.log(y_pred_train)))))\n",
    "    #print('test mse: {}'.format(mean_squared_error(y_test, y_pred_test)))\n",
    "    #print('test rmse: {}'.format(np.sqrt(mean_squared_error(y_test, y_pred_test))))\n",
    "    print('test rmsle: {}'.format(np.sqrt(mean_squared_error(np.log(y_test), np.log(y_pred_test)))))\n",
    "    #print('test r2: {}'.format(r2_score(y_test, y_pred_test)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max_depth = 3\n",
      "train rmsle: 0.1182789710043338\n",
      "test rmsle: 0.12194658508904342\n",
      "\n",
      "For max_depth = 5\n",
      "train rmsle: 0.10820958457701117\n",
      "test rmsle: 0.11807684830463812\n",
      "\n",
      "For max_depth = 7\n",
      "train rmsle: 0.09915424231983065\n",
      "test rmsle: 0.11645675834939422\n",
      "\n",
      "For max_depth = 9\n",
      "train rmsle: 0.09273582349463858\n",
      "test rmsle: 0.1142312526149283\n",
      "\n",
      "For max_depth = 11\n",
      "train rmsle: 0.08966120595668073\n",
      "test rmsle: 0.11847751816095213\n",
      "\n",
      "For max_depth = 13\n",
      "train rmsle: 0.08881680704168372\n",
      "test rmsle: 0.11860233830580175\n",
      "\n",
      "For max_depth = -1\n",
      "train rmsle: 0.0883559672264315\n",
      "test rmsle: 0.11693532175847905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_depths = list(np.arange(3,15,step=2))+[-1]\n",
    "\n",
    "for depth in max_depths:\n",
    "    lightgbm_regr = LGBMRegressor(lambda_l1=1.0, feature_fraction=0.30, num_leaves=31, bagging_fraction=0.5, \n",
    "                                 bagging_freq=5, max_depth=depth)    \n",
    "    lightgbm_regr.fit(X_train_imp_tr_enc_sc, y_train)\n",
    "\n",
    "    y_pred_train = lightgbm_regr.predict(X_train_imp_tr_enc_sc)\n",
    "    y_pred_test = lightgbm_regr.predict(X_test_imp_tr_enc_sc)\n",
    "   \n",
    "    print(\"For max_depth = {}\".format(depth))\n",
    "    #print('train mse: {}'.format(mean_squared_error(y_train, y_pred_train)))\n",
    "    #print('train rmse: {}'.format(np.sqrt(mean_squared_error(y_train, y_pred_train))))\n",
    "    #print('train r2: {}'.format(r2_score(y_train, y_pred_train)))\n",
    "    print('train rmsle: {}'.format(np.sqrt(mean_squared_error(np.log(y_train), np.log(y_pred_train)))))\n",
    "    #print('test mse: {}'.format(mean_squared_error(y_test, y_pred_test)))\n",
    "    #print('test rmse: {}'.format(np.sqrt(mean_squared_error(y_test, y_pred_test))))\n",
    "    print('test rmsle: {}'.format(np.sqrt(mean_squared_error(np.log(y_test), np.log(y_pred_test)))))\n",
    "    #print('test r2: {}'.format(r2_score(y_test, y_pred_test)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse: 384040401.9021788\n",
      "train rmse: 19596.948790619903\n",
      "train r2: 0.9384928342893317\n",
      "train rmsle: 0.09273582349463858\n",
      "\n",
      "test mse: 977558046.7978072\n",
      "test rmse: 31265.924691232263\n",
      "test rmsle: 0.1142312526149283\n",
      "test r2: 0.857750051327447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# best model so far\n",
    "\n",
    "lightgbm_regr = LGBMRegressor(lambda_l1=1.0, feature_fraction=0.30, num_leaves=31, bagging_fraction=0.50, \n",
    "                                 bagging_freq=5, max_depth=9)\n",
    "\n",
    "lightgbm_regr.fit(X_train_imp_tr_enc_sc, y_train)\n",
    "\n",
    "y_pred_train = lightgbm_regr.predict(X_train_imp_tr_enc_sc)\n",
    "y_pred_test = lightgbm_regr.predict(X_test_imp_tr_enc_sc)\n",
    "\n",
    "print('train mse: {}'.format(mean_squared_error(y_train, y_pred_train)))\n",
    "print('train rmse: {}'.format(np.sqrt(mean_squared_error(y_train, y_pred_train))))\n",
    "print('train r2: {}'.format(r2_score(y_train, y_pred_train)))\n",
    "print('train rmsle: {}'.format(np.sqrt(mean_squared_error(np.log(y_train), np.log(y_pred_train)))))\n",
    "print()   \n",
    "print('test mse: {}'.format(mean_squared_error(y_test, y_pred_test)))\n",
    "print('test rmse: {}'.format(np.sqrt(mean_squared_error(y_test, y_pred_test))))\n",
    "print('test rmsle: {}'.format(np.sqrt(mean_squared_error(np.log(y_test), np.log(y_pred_test)))))\n",
    "print('test r2: {}'.format(r2_score(y_test, y_pred_test)))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11423057858674021"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_log_error(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with all data and evaluate again on test data set\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
